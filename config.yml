model_path: /Users/studentone/Documents/LLM_inference/DeepSeek-R1-Distill-Qwen-32B
network_backend: mlx_mpi
mpi:
  interface: bridge0
  num_ranks: 2
tcp:
  port: 12345
tensor_shapes:
  hidden_state:
    dtype: float16  # this will override the default in config.py
  logits:
    dtype: float16  # this will override the default in config.py